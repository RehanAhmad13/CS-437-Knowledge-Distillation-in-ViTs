# RehanAhmad13-CS-437-Knowledge-Distillation-in-ViTs
Contains my project carried out for the course CS-437 Deep Learning. My idea was to use feature-based knowledge distillation by introducing metrics such as mean-square, Cross-Entropy loss and KL Divergence to encourage the student ViT to follow the patterns of teacher ViT. The following repository contains my final report. To see the associated code, check out: https://github.com/rehandelta/ViT-Teacher-Student-Distillation

